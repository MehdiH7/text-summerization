{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "37ac6f8b",
      "metadata": {
        "id": "37ac6f8b"
      },
      "outputs": [],
      "source": [
        "import re # regular expression library\n",
        "import nltk # natural language toolkit library\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b11bc44b",
      "metadata": {
        "id": "b11bc44b"
      },
      "outputs": [],
      "source": [
        "original_text = \"\"\"Artificial intelligence is human like intelligence.\n",
        "                   It is the study of intelligent artificial agents.\n",
        "                   Science and engineering to produce intelligent machines.\n",
        "                   Solve problems and have intelligence.\n",
        "                   Related to intelligent behavior.\n",
        "                   Developing of reasoning machines.\n",
        "                   Learn from mistakes and successes.\n",
        "                   Artificial Intelligence is related to reasoning in everyday situations sasdasdas.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a880eafe",
      "metadata": {
        "id": "a880eafe",
        "outputId": "e9d814ac-3611-48dc-8a2d-432b7c104c16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Artificial intelligence is human like intelligence.\\n                   It is the study of intelligent artificial agents.\\n                   Science and engineering to produce intelligent machines.\\n                   Solve problems and have intelligence.\\n                   Related to intelligent behavior.\\n                   Developing of reasoning machines.\\n                   Learn from mistakes and successes.\\n                   Artificial Intelligence is related to reasoning in everyday situations sasdasdas.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "original_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d986aaae",
      "metadata": {
        "id": "d986aaae"
      },
      "outputs": [],
      "source": [
        "original_text = re.sub(r'\\s+', ' ', original_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "afc2e1c2",
      "metadata": {
        "id": "afc2e1c2",
        "outputId": "034d1e98-a638-4acf-a9c3-2fe98c0ef6c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Artificial intelligence is human like intelligence. It is the study of intelligent artificial agents. Science and engineering to produce intelligent machines. Solve problems and have intelligence. Related to intelligent behavior. Developing of reasoning machines. Learn from mistakes and successes. Artificial Intelligence is related to reasoning in everyday situations sasdasdas.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "original_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "59a3fdf7",
      "metadata": {
        "id": "59a3fdf7",
        "outputId": "496d1298-dc48-4d47-d1af-9478cf3c5b48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cd4e2ebe",
      "metadata": {
        "id": "cd4e2ebe",
        "outputId": "900ee7ce-185e-4a27-b57c-34a33c07f846",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "37706f6e",
      "metadata": {
        "id": "37706f6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e95624cd-254c-4968-e53b-39bd4fd8c184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english') #these are the words in english that have no value and we are going to remve them\n",
        "print(stopwords)\n",
        "len(stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ee94c12f",
      "metadata": {
        "id": "ee94c12f",
        "outputId": "e2c3fe75-2d2b-4fec-8358-9d4c737129ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b0b5ad55",
      "metadata": {
        "id": "b0b5ad55"
      },
      "outputs": [],
      "source": [
        "def preprocess(text): # defining our function and it recieves Text as parameter and will do 3 things for us (lower case, tokenize and removal of the punctuation)\n",
        "    formatted_text = text.lower() # this function lower here makes the texts in Lowercase (firts function)\n",
        "    \n",
        "    tokens = [] # made new variable which includes each one of the words we have in the string\n",
        "    for token in nltk.word_tokenize(formatted_text):\n",
        "        tokens.append(token)\n",
        "        print(tokens)\n",
        "    \n",
        "    tokens = [word for word in tokens if word not in stopwords and word not in string.punctuation] #check the tokens variable and remove the one that matches in stopwords and that matches in punctuations\n",
        "    \n",
        "    \n",
        "    formatted_text = ' '.join(element for element in tokens)\n",
        "    \n",
        "    return formatted_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "396027f7",
      "metadata": {
        "id": "396027f7",
        "outputId": "684bea5f-ccb9-4eac-ba90-9cb2f9794ddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'artificial intelligence human like intelligence study intelligent artificial agents science engineering produce intelligent machines solve problems intelligence related intelligent behavior developing reasoning machines learn mistakes successes artificial intelligence related reasoning everyday situations sasdasdas'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "formatted_text = preprocess(original_text) #now make a variable to implement our function to the text we want\n",
        "formatted_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f41ae91b",
      "metadata": {
        "id": "f41ae91b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6434ee3-ba03-4ae9-b3d2-4b14af73b1ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'intelligence': 4, 'artificial': 3, 'intelligent': 3, 'machines': 2, 'related': 2, 'reasoning': 2, 'human': 1, 'like': 1, 'study': 1, 'agents': 1, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "word_frequency = nltk.FreqDist(nltk.word_tokenize(formatted_text)) # made a new variable that store the number of times each word appered in the text\n",
        "word_frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "eee7c8f8",
      "metadata": {
        "id": "eee7c8f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25889cea-7b4b-497b-b204-a1ac3a95d0ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "highest_frequency = max(word_frequency.values()) # we need to find the maximum value (the maximum number a word has appered in text) to make weight for each word\n",
        "highest_frequency"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in word_frequency: # we come up with a loop to devide the frequency of each word to the maximum amount\n",
        "  #print(word)\n",
        "  word_frequency[word] = (word_frequency[word] / highest_frequency)\n"
      ],
      "metadata": {
        "id": "MRktCc9-oscA"
      },
      "id": "MRktCc9-oscA",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNPNTvHVpOji",
        "outputId": "ef709d32-30ee-4fe0-b6ef-2ff029c66d2c"
      },
      "id": "NNPNTvHVpOji",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'intelligence': 0.25, 'artificial': 0.1875, 'intelligent': 0.1875, 'machines': 0.125, 'related': 0.125, 'reasoning': 0.125, 'human': 0.0625, 'like': 0.0625, 'study': 0.0625, 'agents': 0.0625, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MCCvSMsdr-wa"
      },
      "id": "MCCvSMsdr-wa",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}